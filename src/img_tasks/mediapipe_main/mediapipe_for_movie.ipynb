{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/mediapipe/blob/main/mediapipe_for_movie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuQfLvpuJkb0"
      },
      "source": [
        "#@title **set up**\n",
        "\n",
        "# install mediapipe\n",
        "!pip install mediapipe\n",
        "\n",
        "# clone github code\n",
        "!git clone https://github.com/cedro3/mediapipe.git\n",
        "%cd mediapipe/\n",
        "\n",
        "# initial setting\n",
        "import mediapipe as mp\n",
        "mp_holistic = mp.solutions.holistic\n",
        "\n",
        "# Initialize MediaPipe Holistic.\n",
        "holistic = mp_holistic.Holistic(\n",
        "    static_image_mode=True, min_detection_confidence=0.5)\n",
        "\n",
        "# Prepare DrawingSpec for drawing the face landmarks later.\n",
        "WHITE_COLOR = (224, 224, 224)\n",
        "BLACK_COLOR = (0, 0, 0)\n",
        "RED_COLOR = (0, 0, 255)\n",
        "GREEN_COLOR = (0, 128, 0)\n",
        "BLUE_COLOR = (255, 0, 0)\n",
        "mp_drawing = mp.solutions.drawing_utils \n",
        "drawing_face_spec = mp_drawing.DrawingSpec(color=WHITE_COLOR, thickness=1, circle_radius=1)\n",
        "drawing_pose_spec = mp_drawing.DrawingSpec(color=WHITE_COLOR, thickness=3, circle_radius=3)\n",
        "drawing_hand_spec = mp_drawing.DrawingSpec(color=WHITE_COLOR, thickness=3, circle_radius=3)\n",
        "drawing_dot_spec = mp_drawing.DrawingSpec(color=RED_COLOR, thickness=2, circle_radius=3)\n",
        "\n",
        "# define fuction\n",
        "from function import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **video-to-frames**\n",
        "#@markdown upload video(mp4) with sound to movie/video folder\n",
        " \n",
        "video = 'satomi.mp4' #@param {type:\"string\"}\n",
        "video_file = 'video/'+video\n",
        "image_dir='frames/'\n",
        "image_file='%s.jpg'\n",
        " \n",
        "# video_2_images\n",
        "reset_folder('frames')\n",
        "fps, i, interval = video_2_images(video_file, image_dir, image_file)\n",
        " \n",
        "# display strat frame\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('frames/000000.jpg')\n",
        "cv2_imshow(img)\n",
        " \n",
        "# display parameter\n",
        "print('fps = ', fps)\n",
        "print('frames = ', i)\n",
        "print('interval = ', interval)"
      ],
      "metadata": {
        "id": "n-B0nVeD_5I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs2IYWOGtCGj"
      },
      "source": [
        "#@title **MediaPipe from frames to images**\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import glob\n",
        "from tqdm import tqdm ###\n",
        "\n",
        "# reset images folder\n",
        "reset_folder('images')\n",
        "\n",
        "# image file names to files in list format\n",
        "files=[]\n",
        "for name in sorted(glob.glob('./frames/*.jpg')):\n",
        "    files.append(name)\n",
        "\n",
        "# Read images with OpenCV.\n",
        "images = {name: cv2.imread(name) for name in files}\n",
        "\n",
        "#for name, image in images.items():\n",
        "for name, image in tqdm(images.items()):  \n",
        "  # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
        "  results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  # Draw pose landmarks.\n",
        "  annotated_image = image.copy()\n",
        "  mp_drawing.draw_landmarks(\n",
        "      image=annotated_image,\n",
        "      landmark_list=results.left_hand_landmarks,\n",
        "      connections=mp_holistic.HAND_CONNECTIONS,\n",
        "      landmark_drawing_spec=drawing_dot_spec,\n",
        "      connection_drawing_spec=drawing_hand_spec)\n",
        "  mp_drawing.draw_landmarks(\n",
        "      image=annotated_image,\n",
        "      landmark_list=results.right_hand_landmarks,\n",
        "      connections=mp_holistic.HAND_CONNECTIONS,\n",
        "      landmark_drawing_spec=drawing_dot_spec,\n",
        "      connection_drawing_spec=drawing_hand_spec)\n",
        "  mp_drawing.draw_landmarks(\n",
        "      image=annotated_image, \n",
        "      landmark_list=results.face_landmarks, \n",
        "      connections=mp_holistic.FACEMESH_TESSELATION,  ###\n",
        "      landmark_drawing_spec=drawing_face_spec,\n",
        "      connection_drawing_spec=drawing_face_spec)\n",
        "  mp_drawing.draw_landmarks(\n",
        "      image=annotated_image, \n",
        "      landmark_list=results.pose_landmarks, \n",
        "      connections=mp_holistic.POSE_CONNECTIONS,\n",
        "      landmark_drawing_spec=drawing_pose_spec,\n",
        "      connection_drawing_spec=drawing_pose_spec)\n",
        "  \n",
        "  save_name = 'images/'+os.path.basename(name) ###\n",
        "  cv2.imwrite(save_name, annotated_image)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **make movie from images**\n",
        "#@markdownã€€check with_sound if the video has sound\n",
        "with_sound = False #@param {type:\"boolean\"}\n",
        "fps_r = fps/interval\n",
        "\n",
        "print('making movie...')\n",
        "if with_sound ==  True:  \n",
        "  ! ffmpeg -y -r $fps_r -i images/%6d.jpg -vcodec libx264 -pix_fmt yuv420p -loglevel error out.mp4\n",
        "  # audio extraction/addition\n",
        "  print('preparation for sound...')\n",
        "  ! ffmpeg -y -i $video_file -loglevel error sound.mp3\n",
        "  ! ffmpeg -y -i out.mp4 -i sound.mp3 -loglevel error output.mp4\n",
        "else:\n",
        "  ! ffmpeg -y -r $fps_r -i images/%6d.jpg -vcodec libx264 -pix_fmt yuv420p -loglevel error output.mp4\n",
        "\n",
        "display_mp4('output.mp4')"
      ],
      "metadata": {
        "id": "Ym_QZlqrCM0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **download movie** (chrome)\n",
        "from google.colab import files\n",
        "files.download('output.mp4')"
      ],
      "metadata": {
        "id": "3PDnNaxhSHe4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
